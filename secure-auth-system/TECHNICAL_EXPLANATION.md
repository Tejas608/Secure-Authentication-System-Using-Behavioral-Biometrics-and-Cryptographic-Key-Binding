# ðŸ”§ Secure Authentication System - Deep Technical Explanation

## How Everything Works Under the Hood

---

# PART 1: CRYPTOGRAPHY - DETAILED MECHANISMS

## 1.1 RSA Key Generation (2048-bit)

### What Happens When a User Registers

```
generate_rsa_keypair() function flow:

Step 1: Generate Private Key
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ private_key = rsa.generate_private_key(         â”‚
â”‚     public_exponent = 65537,  (standard value)  â”‚
â”‚     key_size = 2048           (bits)            â”‚
â”‚ )                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    â†“ â†“ â†“ â†“ â†“ (random number generation happens here)
        â†“
  Result: A 2048-bit number that is:
  - Hard to factor (security based on this)
  - Only known by server
  - Kept encrypted in users.json

Step 2: Generate Public Key from Private Key
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ public_key = private_key.public_key()            â”‚
â”‚ # Mathematically derived from private key       â”‚
â”‚ # But can't be reversed back to private key     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
  Result: Derived public key that:
  - Is mathematically linked to private key
  - Can verify signatures made with private key
  - Safe to share with anyone

Step 3: Encode to PEM Format
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ private_pem = private_key.private_bytes(         â”‚
â”‚     encoding = Encoding.PEM,                    â”‚
â”‚     format = PrivateFormat.PKCS8,              â”‚
â”‚     encryption_algorithm = NoEncryption()       â”‚
â”‚ )                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
  Output: String like:
  -----BEGIN PRIVATE KEY-----
  MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEA...
  ...long base64 string...
  -----END PRIVATE KEY-----

Similarly for public_key â†’ public_pem
```

### Mathematical Basis of RSA

```
Private Key Components:
  p, q = Two large prime numbers (each ~1024 bits)
  n = p Ã— q = 2048 bits (modulus)
  d = Decryption exponent (secret)

Public Key Components:
  n = Same modulus (p Ã— q)
  e = 65537 (encryption exponent, public standard)

Key Security Property:
  If factoring n back to p and q is hard
  â†’ Then recovering d from e is hard
  â†’ RSA security holds

For 2048-bit RSA:
  Estimated security level â‰ˆ 112 bits (NIST equivalent)
  Cost to break: ~$10^9 with current technology
  Time to break: ~300 trillion years (classical computers)
```

### Why Store in users.json

```json
{
  "username": {
    "private_key": "-----BEGIN PRIVATE KEY-----\n...",
    "public_key": "-----BEGIN PUBLIC KEY-----\n..."
  }
}
```

**Private Key Security:**

- Never leaves server
- Used ONLY for binding token creation
- Not shared with frontend
- Server is trusted entity

**Public Key Storage:**

- Used for verification
- Could theoretically be sent to client
- Currently stored in users.json (server-side)

---

## 1.2 HKDF - Key Derivation Function (Deep Dive)

### Problem It Solves

```
Scenario: We have keystroke features [114.5, 36.1, 103.9, ...]

Question: How do we convert these floats into a cryptographic key?

Naive approach (WRONG):
â”œâ”€ Convert features to bytes directly
â”œâ”€ Use as encryption key
â””â”€ Problem: Too predictable, not enough entropy

Correct approach (HKDF):
â”œâ”€ Start with feature bytes as "seed"
â”œâ”€ Apply cryptographic extraction/expansion
â”œâ”€ Generate 256-bit key with proper entropy distribution
â””â”€ Result: Cryptographically strong key
```

### HKDF Algorithm (HMAC-based Extract-and-Expand KDF)

```python
# From: crypto_utils.py

def derive_binding_key(features: List[float]) -> bytes:
    # Step 1: Convert features to bytes
    seed = _features_to_bytes(features)
    # Result: "114.500000,36.100000,103.900000,..." (comma-separated)

    # Step 2: Apply HKDF
    hkdf = HKDF(
        algorithm = hashes.SHA256(),      # Hash algorithm
        length = 32,                       # Output: 32 bytes = 256 bits
        salt = None,                       # No salt (optional)
        info = b"keystroke-binding"        # Context string
    )

    # Step 3: Derive key
    key = hkdf.derive(seed)
    # Result: 32 random-looking bytes
    return key
```

### Step-by-Step HKDF Process

```
Input Features:
[114.5, 36.1, 103.9, 268.7, 117.2, 250.2, ...]
    â†“
Convert to String Bytes:
"114.500000,36.100000,103.900000,..." â†’ binary bytes (seed)
    â†“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EXTRACT Phase (Pseudorandom value from IKM):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    salt (if provided)
         â†“
    PRK = HMAC-Hash(salt, seed)
         â†“
    Result: Fixed-length PRK (32 bytes from SHA256)
    â†“
    (Actually in this implementation, salt=None, so just seed is hashed)
    â†“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EXPAND Phase (Generate desired output length):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    T(0) = empty
    T(1) = HMAC-Hash(PRK, T(0) + info + 0x01)
    T(2) = HMAC-Hash(PRK, T(1) + info + 0x02)
    ... (repeat until we have 32 bytes)

    OKM = T(1) + T(2) + ... (take first 32 bytes)
    â†“
    Result: 32 bytes of cryptographically derived key
    â†“
Final Output:
32 random-looking bytes that are:
- Deterministic (same input â†’ same output)
- Uniform (each bit is ~50% 0 or 1)
- Sensitive (tiny input change â†’ completely different output)
```

### Why HKDF is Better Than Raw Hashing

```
Naive: SHA256(features_bytes) â†’ 32 bytes
â”œâ”€ Problem: Direct hash of input
â”œâ”€ Problem: No context string
â”œâ”€ Problem: Input space maps directly to output
â””â”€ Security: Weak if input has patterns

HKDF: HKDF-SHA256(features_bytes, info="keystroke-binding") â†’ 32 bytes
â”œâ”€ Benefit: Extraction removes patterns
â”œâ”€ Benefit: Expansion uses HMAC (keyed hash)
â”œâ”€ Benefit: Context string ("keystroke-binding") prevents reuse
â”œâ”€ Benefit: Approved by NIST and cryptographic standards
â””â”€ Security: Strong, even if input has patterns
```

### Example Calculation

```
Feature vector: [114.5, 36.1, 103.9, 268.7, 117.2, 250.2, 2524.2, 10.0, 0.004, 0.44, 36.1, 0.44, 0.32, 0.99, 0.9, 0.44]

Step 1 - Convert to bytes:
"114.500000,36.100000,103.900000,268.700000,117.200000,250.200000,2524.200000,10.000000,0.004000,0.440000,36.100000,0.440000,0.320000,0.990000,0.900000,0.440000"

(Total: 167 bytes)

Step 2 - HKDF with SHA256:
Input seed: 167 bytes (from above)
Hash algorithm: SHA256 (32-byte output per call)
Context: "keystroke-binding" (18 bytes)

Step 3 - Internal HMAC operations (simplified):
PRK = HMAC-SHA256(167-byte-seed)
    = 32 bytes of pseudorandom

T(1) = HMAC-SHA256(PRK, empty + "keystroke-binding" + 0x01)
     = 32 bytes

Output: First 32 bytes of T(1)
      = 32-byte cryptographic key

Hex representation might look like:
a4 2f 8e 3c 1d 9b e7 4a 2c 5f 8d 3e 7a 1b 9c 4d
2e 6f 3a 8d 4c 7e 9b 1f 5a 2d 8e 3c 7f 1a 4e 9b

(32 bytes total)
```

---

## 1.3 Cryptographic Binding - Feature Locking

### The Problem We're Solving

```
Scenario: Attacker steals users.json file

Attack 1: "I'll steal the feature_template and use it to login"
â””â”€ Problem: They have template but need to match it exactly
â””â”€ But keystroke features naturally vary by Â±5-10%

Attack 2: "I'll modify the template to be more lenient"
â””â”€ Problem: But how do they verify their modification is valid?
â””â”€ They'd need to know the secret key!

Attack 3: "I'll copy someone else's public key"
â””â”€ Problem: Doesn't help - binding is to THEIR specific features

Solution: Cryptographic Binding
â””â”€ Lock features to public key using HKDF + SHA256
â””â”€ Can't change one without invalidating the other
```

### Binding Token Creation Process

```python
def bind_public_key(public_key_pem: str, features: List[float]) -> str:
    """
    Input:
      public_key_pem: RSA public key as string (2048-bit)
      features: 16-dimensional keystroke feature vector

    Output:
      binding_token: 43-character base64 string (256 bits encoded)
    """

    # Step 1: Derive cryptographic key from features
    key = derive_binding_key(features)
    # Result: 32 bytes derived using HKDF-SHA256
    #   if features change â†’ key changes completely

    # Step 2: Create binding
    digest = hashlib.sha256(
        key +                    # 32 bytes (derived from features)
        public_key_pem.encode()  # ~450 bytes (RSA public key as text)
    ).digest()
    # Result: SHA256(key + public_key) = 32 bytes

    # Step 3: Encode to base64
    binding_token = base64.urlsafe_b64encode(digest).decode()
    # Result: "-zGxh4urMOMwVcWXUdMFX9fHaxEyWgwAgyYiU8wy61o="
    #         (43 characters representing 32 bytes)

    return binding_token
```

### Visual Flow

```
Registration Phase:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User enters password twice             â”‚
â”‚ â””â”€ Captures keystrokes                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Extract 16-D feature vectorâ”‚
        â”‚ [114.5, 36.1, 103.9, ...]  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ HKDF-SHA256(features)              â”‚
        â”‚ â†’ 32-byte key                      â”‚
        â”‚ (deterministic from features)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Generate RSA keypair               â”‚
        â”‚ public_key = 2048-bit RSA public   â”‚
        â”‚ private_key = 2048-bit RSA private â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ SHA256(32-byte-key + public_key)   â”‚
        â”‚ â†’ 32-byte digest                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Base64 encode digest               â”‚
        â”‚ â†’ binding_token (43 chars)         â”‚
        â”‚ "-zGxh4urMOMwVcWXUdMFX9fHax..."   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Store in users.json:               â”‚
        â”‚ {                                  â”‚
        â”‚   "public_key": "...",            â”‚
        â”‚   "binding_token": "...",         â”‚
        â”‚   "feature_template": [...]       â”‚
        â”‚ }                                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Login Phase - Verification

```python
def verify_binding(public_key_pem: str, features: List[float], binding_token: str) -> bool:
    """
    Input:
      public_key_pem: Stored public key from users.json
      features: New keystroke features from login attempt
      binding_token: Stored binding token from users.json

    Return:
      True if binding is valid (features match)
      False if binding is invalid (features don't match)
    """

    try:
        # Step 1: Recalculate binding token from current features
        expected = bind_public_key(public_key_pem, features)
        # If login features are similar to registration features:
        # â†’ Same key derived from HKDF
        # â†’ Same SHA256(key + public_key)
        # â†’ Same binding_token

        # Step 2: Compare using constant-time comparison
        return hashlib.compare_digest(expected, binding_token)
        # compare_digest() prevents timing attacks
        # (doesn't short-circuit on first difference)

    except Exception:
        return False
```

### Example Verification Scenario

```
Registration:
â”œâ”€ Features extracted: [114.5, 36.1, 103.9, ...]
â”œâ”€ Key derived: abc123...xyz (32 bytes from HKDF)
â”œâ”€ Public key: -----BEGIN PUBLIC KEY-----\n...
â”œâ”€ Hash: SHA256(abc123...xyz + public_key)
â””â”€ Token stored: "-zGxh4urMOMwVcWXUdMFX9fHaxEyWgwAgyYiU8wy61o="

Login Attempt 1 (Legitimate - Similar Typing):
â”œâ”€ Features extracted: [114.3, 36.2, 103.8, ...] (slight variation)
â”œâ”€ Key derived: abc123...xyz (SAME! Similar features â†’ same key)
â”œâ”€ Hash: SHA256(abc123...xyz + public_key) (SAME!)
â”œâ”€ Token calculated: "-zGxh4urMOMwVcWXUdMFX9fHaxEyWgwAgyYiU8wy61o="
â”œâ”€ Comparison: calculated == stored? YES âœ“
â””â”€ Result: ACCEPT

Login Attempt 2 (Attack - Different Typing):
â”œâ”€ Features extracted: [150.0, 50.0, 130.0, ...] (impostor typing)
â”œâ”€ Key derived: xyz999...abc (DIFFERENT! Different features â†’ different key)
â”œâ”€ Hash: SHA256(xyz999...abc + public_key) (DIFFERENT!)
â”œâ”€ Token calculated: "9mK7fPq2rStUvWxYzAbCdEfGhIjKlMnOpQrStUvWxYz"
â”œâ”€ Comparison: calculated == stored? NO âœ—
â””â”€ Result: REJECT
```

### Security Properties of Binding

```
Tamper Property 1: Can't change features without invalidating token
â”œâ”€ If attacker changes one feature by 0.1
â”œâ”€ â†’ Derived key changes completely (HKDF avalanche effect)
â”œâ”€ â†’ SHA256 hash changes
â”œâ”€ â†’ Binding token becomes invalid
â””â”€ Detection: Token mismatch â†’ REJECT

Tamper Property 2: Can't change token for same features
â”œâ”€ SHA256 is one-way function
â”œâ”€ Given old_token, can't find new_token for modified features
â”œâ”€ Would need to brute-force: 2^256 possibilities
â””â”€ Computationally infeasible

Tamper Property 3: Can't swap between users
â”œâ”€ Token is tied to specific public_key
â”œâ”€ If attacker uses User A's features with User B's public_key
â”œâ”€ â†’ SHA256(User_A_key + User_B_public_key) â‰  User_A_token
â”œâ”€ â†’ Binding fails
â””â”€ Each user's token is unique

Resistance Property: Resistance to offline attacks
â”œâ”€ Even if attacker has users.json (features + token + public_key)
â”œâ”€ Can't verify if calculated token matches stored token?
â”œâ”€ Without trying all 2^256 possibilities? (billion years)
â”œâ”€ Compare_digest() prevents timing attacks too
â””â”€ Very secure offline
```

---

## 1.4 Password Hashing with PBKDF2

### Problem: Plain Password Storage

```
Vulnerability:
â””â”€ If users.json is leaked, attacker reads passwords directly
â””â”€ Can login as any user immediately

Solution: Hash the password
â””â”€ Store: hash(password)
â””â”€ On login: hash(entered_password) == stored_hash?
â””â”€ Even if DB is leaked, passwords are not revealed
```

### PBKDF2 Algorithm (Password-Based Key Derivation Function 2)

```python
# Pseudocode of password hashing:

salt = generate_random_bytes(32)  # 256-bit random salt

hash = PBKDF2(
    password = "MyPassword123!",
    salt = salt,
    hash_function = "SHA256",
    iterations = 100000,
    dkLen = 32  # 256-bit output
)

# Store: (salt, hash)
```

### Why 100,000 Iterations?

```
Iteration count determines slowness:

1 iteration:
â”œâ”€ Speed: ~1 microsecond per hash
â”œâ”€ Attacker can try: 1,000,000 passwords/second
â””â”€ Risk: Fast dictionary attack

100,000 iterations:
â”œâ”€ Speed: ~100 milliseconds per hash (on modern CPU)
â”œâ”€ Attacker can try: ~10 passwords/second max
â”œâ”€ With 2^80 passwords to try: 2^80 / 10 â‰ˆ 10^24 seconds â‰ˆ 10^16 years
â””â”€ Secure against brute force

Cost analysis:
â”œâ”€ Legitimate user: Wait 100ms for login (acceptable)
â”œâ”€ Attacker trying 1 million passwords: Wait 10^7 seconds â‰ˆ 116 days
â””â”€ Attacker trying password list (most common 1 million): Still takes days
```

### Why Salt?

```
Without salt (VULNERABLE):
â”œâ”€ Same password always produces same hash
â”œâ”€ Two users with same password have same hash (reveals patterns)
â”œâ”€ Precomputed "rainbow tables" work
â”œâ”€ Example: "password123" â†’ hash123abc
â”‚           Anyone can google "hash123abc" â†’ find it precomputed
â””â”€ Attack: Try all 100,000 most common passwords once, store results

With salt (SECURE):
â”œâ”€ Same password produces different hash for each user (due to unique salt)
â”œâ”€ "password123" + salt1 â†’ hash_abc
â”œâ”€ "password123" + salt2 â†’ hash_xyz
â”œâ”€ Can't use rainbow tables (would need 2^128 entries per password)
â”œâ”€ Attacker must compute PBKDF2 for each password attempt
â””â”€ Attack: Much harder, requires live computation
```

### Verification Process on Login

```python
def verify_password(entered_password: str, stored_salt: str, stored_hash: str) -> bool:
    # Step 1: Hash entered password with stored salt
    calculated_hash = PBKDF2(
        password = entered_password,
        salt = stored_salt,
        iterations = 100000
    )

    # Step 2: Compare using constant-time comparison
    return constant_time_compare(calculated_hash, stored_hash)

    # If passwords match:
    #   calculated_hash == stored_hash â†’ Return True
    # If passwords don't match:
    #   calculated_hash â‰  stored_hash â†’ Return False
```

### Example Hash Verification

```
At Registration:
â”œâ”€ User enters: "MyPassword123!"
â”œâ”€ Generate salt: "1+nKhK53T2OWatCY9AFRFA==" (random, base64)
â”œâ”€ Hash: PBKDF2("MyPassword123!" + salt, 100k iterations)
â”‚       = "73GFohybqJoXEGRSAocGpsQBEWDYcAIrfjGFE0FVv5A="
â”œâ”€ Store both salt and hash in users.json
â””â”€ (Password itself is NEVER stored)

At Login:
â”œâ”€ User enters: "MyPassword123!"
â”œâ”€ Retrieve stored salt: "1+nKhK53T2OWatCY9AFRFA=="
â”œâ”€ Hash entered password: PBKDF2("MyPassword123!" + salt, 100k iterations)
â”‚                        = "73GFohybqJoXEGRSAocGpsQBEWDYcAIrfjGFE0FVv5A="
â”œâ”€ Compare: calculated == stored?
â”‚           "73G...Fv5A==" == "73G...Fv5A==" â†’ YES âœ“
â””â”€ Result: Password correct, continue to next gate

Attack Scenario - Wrong Password:
â”œâ”€ Attacker enters: "WrongPassword123!"
â”œâ”€ Hash entered password: PBKDF2("WrongPassword123!" + salt, 100k iterations)
â”‚                        = "9mK7fPq2rStUvWxYzAbCdEfGhIjKlMnOpQrStUvWxY="
â”œâ”€ Compare: calculated == stored?
â”‚           "9mK...xYz==" != "73G...Fv5A==" â†’ NO âœ—
â””â”€ Result: Password incorrect, log as failed attempt
```

---

# PART 2: CYBERSECURITY - AUTHENTICATION GATES

## 2.1 Six-Gate Sequential Authentication

### Architecture Diagram

```
LOGIN ATTEMPT
    â†“
    â”œâ”€â†’ [GATE 1] Password Hash Verification
    â”‚       â”œâ”€ PBKDF2(entered_pwd + salt) == stored_hash?
    â”‚       â”œâ”€ YES â†’ Continue
    â”‚       â””â”€ NO â†’ REJECT (label=0, tag=fail_pw)
    â”‚
    â”œâ”€â†’ [GATE 2] Feature Extraction
    â”‚       â”œâ”€ Parse keystroke events (keydown/keyup)
    â”‚       â”œâ”€ Calculate 16 features (dwell, flight, cadence, etc.)
    â”‚       â””â”€ Result: 16-D feature vector
    â”‚
    â”œâ”€â†’ [GATE 3] Tempo Distortion Attack Detection
    â”‚       â”œâ”€ Compare current features with stored template
    â”‚       â”œâ”€ Detect uniform speed changes
    â”‚       â”œâ”€ ATTACK â†’ REJECT (tag=tempo_attack)
    â”‚       â””â”€ NORMAL â†’ Continue
    â”‚
    â”œâ”€â†’ [GATE 4] Behavioral Envelope (Ensemble Model)
    â”‚       â”œâ”€ Load Isolation Forest + LOF models
    â”‚       â”œâ”€ Calculate anomaly scores
    â”‚       â”œâ”€ BOTH flag anomaly â†’ Continue to Gate 5
    â”‚       â””â”€ At least one is normal â†’ Continue
    â”‚
    â”œâ”€â†’ [GATE 5] Rhythm Consistency Check
    â”‚       â”œâ”€ Calculate: rhythm_consistency = flight_std / flight_mean
    â”‚       â”œâ”€ If < 0.05 â†’ BOT DETECTED â†’ REJECT
    â”‚       â””â”€ If >= 0.05 â†’ HUMAN TYPING â†’ Continue
    â”‚
    â”œâ”€â†’ [GATE 6] Cryptographic Binding Verification
    â”‚       â”œâ”€ Verify binding_token matches current features
    â”‚       â”œâ”€ MATCH â†’ ACCEPT âœ“
    â”‚       â””â”€ NO MATCH â†’ REJECT âœ—
    â”‚
    â””â”€â†’ ADAPTIVE LEARNING (on accept only)
        â”œâ”€ Save to keystrokes.csv (label=1)
        â”œâ”€ Retrain model with all samples
        â””â”€ Update feature_template & feature_std
```

### Why Sequential Gates?

```
Benefit 1: Defense in Depth
â”œâ”€ If Gate 1 fails â†’ Stop (password is first line)
â”œâ”€ If Gate 2 fails â†’ Stop (features don't compute)
â”œâ”€ If Gate 3 fails â†’ Detect replay attacks early
â”œâ”€ If Gate 4 fails â†’ Ensemble catches anomalies
â”œâ”€ If Gate 5 fails â†’ Bot detection stops scripts
â”œâ”€ If Gate 6 fails â†’ Final cryptographic check
â””â”€ Attacker must bypass ALL 6 gates (6 layers of defense)

Benefit 2: Early Rejection Efficiency
â”œâ”€ Wrong password? Reject at Gate 1 (immediate, ~1ms)
â”œâ”€ Bad features? Reject at Gate 3 (early, ~5ms)
â”œâ”€ Saves computation time on obviously wrong attempts
â””â”€ Model training only happens on near-legitimate attempts

Benefit 3: Attack Pattern Detection
â”œâ”€ Gate 1 rejections â†’ Brute force attempts (log all)
â”œâ”€ Gate 3 rejections â†’ Replay/tempo attacks (specific threat)
â”œâ”€ Gate 5 rejections â†’ Bot/script attacks (automation detected)
â””â”€ Forensics: Know exactly which attack was attempted
```

---

## 2.2 Tempo Distortion Attack Detection (Gate 3)

### The Attack

```
Attacker's Plan:
â”œâ”€ Record legitimate user typing password on video
â”œâ”€ Extract keystroke timings from video
â”œâ”€ Replay key presses at DIFFERENT speed (e.g., 2x slower)
â”œâ”€ System should think it's the user (just tired today)
â””â”€ Login succeeds!

Why this might work on naive systems:
â”œâ”€ Slower typing still matches the "password" being typed
â”œâ”€ All features scale uniformly (just multiplied by 2x)
â”œâ”€ Single-threshold model might not catch it
â””â”€ Attacker just needs to match the scaled features
```

### Detection Mechanism

```python
def _analyze_temporal_patterns(login_vec, template_vec) -> Dict:
    """Detect uniform speed changes (tempo attacks)."""

    # Extract timing features (indices 0, 1, 3, 4 = dwell and flight)
    login_dwell_mean = login_vec[0]      # e.g., 114.5 ms
    login_flight_mean = login_vec[3]     # e.g., 268.7 ms

    template_dwell_mean = template_vec[0]  # e.g., 114.2 ms
    template_flight_mean = template_vec[3] # e.g., 268.5 ms

    # Calculate ratios (scale factors)
    if template_dwell_mean > 0.001:
        dwell_ratio = login_dwell_mean / template_dwell_mean
        # If uniform 2x slowdown:
        #   114.5 / 114.2 â‰ˆ 1.003 (small ratio, slight variation)
        # If REAL 2x slowdown attack:
        #   228.0 / 114.2 â‰ˆ 1.996 (exactly 2x)

    if template_flight_mean > 0.001:
        flight_ratio = login_flight_mean / template_flight_mean
        # If uniform 2x slowdown:
        #   537.0 / 268.5 â‰ˆ 1.999 (exactly 2x)
```

### Key Insight: Attack Creates Correlation

```
Legitimate User (Natural Variation):
â”œâ”€ dwell_mean login vs template: 114.5 / 114.2 = 1.003 (0.3% difference)
â”œâ”€ flight_mean login vs template: 268.7 / 268.5 = 1.001 (0.1% difference)
â”œâ”€ dwell_std login vs template: 36.3 / 36.1 = 1.006 (0.6% difference)
â”œâ”€ Ratios are DIFFERENT (not correlated)
â””â”€ Verdict: Natural human variation âœ“

Attack: Uniform 2x Slowdown
â”œâ”€ Keystroke hold time: 114.2 ms â†’ 228.4 ms (exactly 2x)
â”œâ”€ Gap between keys: 268.5 ms â†’ 537.0 ms (exactly 2x)
â”œâ”€ dwell_mean ratio: 228.4 / 114.2 = 1.999 (almost exactly 2x)
â”œâ”€ flight_mean ratio: 537.0 / 268.5 = 1.999 (almost exactly 2x)
â”œâ”€ ALL ratios are SAME (perfectly correlated)
â””â”€ Verdict: Uniform scaling detected = Attack! âœ—
```

### Detection Logic

```python
# From auth.py - _analyze_temporal_patterns()

# Thresholds for detection
NORMAL_VARIATION_THRESHOLD = 0.3  # Ratios can differ by 30%
ATTACK_CORRELATION_THRESHOLD = 0.05  # If all ratios are within 5% of each other

# Calculate all timing ratios
dwell_ratio = login_dwell_mean / template_dwell_mean  # e.g., 1.003
flight_ratio = login_flight_mean / template_flight_mean  # e.g., 1.001

# For natural variation, ratios should differ
# For attacks, ratios should be nearly identical

ratio_difference = abs(dwell_ratio - flight_ratio)
# Natural: 1.003 - 1.001 = 0.002 (0.2% difference) âœ“
# Attack: 1.999 - 1.999 = 0.000 (no difference) âœ—

if ratio_difference < ATTACK_CORRELATION_THRESHOLD:
    return {
        "tempo_attack": True,
        "explanation": "Uniform speed change detected"
    }
else:
    return {
        "tempo_attack": False,
        "explanation": "Natural typing variation"
    }
```

---

## 2.3 Rhythm Consistency Check (Gate 5)

### The Problem: Bot Detection

```
Attacker's Plan:
â”œâ”€ Write simple automation script:
â”‚   for key in "password":
â”‚       simulate keydown
â”‚       wait exactly 100 ms
â”‚       simulate keyup
â”‚       wait exactly 100 ms
â”œâ”€ All keys held for exactly 100ms
â”œâ”€ All gaps are exactly 100ms
â”œâ”€ Perfect uniformity!
â””â”€ Looks like robot typing (too perfect for human)

Why this is suspicious:
â”œâ”€ Real humans have natural variation
â”œâ”€ Each key held for different time (98ms, 102ms, 95ms, ...)
â”œâ”€ Sleep duration slightly varies (101ms, 99ms, 100ms, ...)
â”œâ”€ Perfect uniformity is unnatural
â””â”€ System should detect and reject
```

### Feature: Rhythm Consistency

```python
# From keystroke_features.py

dwell_times = [120, 95, 130, 90, 110]  # Human - varied hold times
# mean = 109 ms
# std = 15 ms
# consistency = 15 / 109 = 0.138 (13.8% variation)

flight_times = [268, 280, 260, 275]  # Human - varied gaps
# mean = 270.75 ms
# std = 8.8 ms
# consistency = 8.8 / 270.75 = 0.032 (3.2% variation)

# Real feature in vector: rhythm_consistency = flight_std / flight_mean
rhythm_consistency_human = 8.8 / 270.75 = 0.0325 âœ“ (natural variation)
```

### Bot/Script Typing

```python
dwell_times = [100, 100, 100, 100, 100]  # Bot - perfectly uniform
# mean = 100 ms
# std = 0 ms
# consistency = 0 / 100 = 0.0

flight_times = [100, 100, 100, 100]  # Bot - perfectly uniform
# mean = 100 ms
# std = 0 ms
# consistency = 0 / 100 = 0.0

rhythm_consistency_bot = 0.0 âœ— (too uniform, bot detected!)
```

### Gate 5 Logic

```python
RHYTHM_CONSISTENCY_THRESHOLD = 0.05  # 5% minimum variation required

if rhythm_consistency < RHYTHM_CONSISTENCY_THRESHOLD:
    # Too uniform - likely a bot or script
    return {
        "status": "REJECT",
        "reason": "Rhythm too uniform - bot detected",
        "tag": "entropy_attack"
    }
else:
    # Natural human variation detected
    return {
        "status": "CONTINUE",
        "reason": "Natural typing rhythm detected"
    }
```

### Why Threshold = 0.05?

```
Analysis of Real Users:
â”œâ”€ Slow, careful typist: rhythm_consistency = 0.08 (8%)
â”œâ”€ Moderate speed: rhythm_consistency = 0.12 (12%)
â”œâ”€ Fast, experienced typist: rhythm_consistency = 0.18 (18%)
â””â”€ All > 0.05 âœ“

Analysis of Bots:
â”œâ”€ Perfectly uniform script: rhythm_consistency = 0.00 (0%)
â”œâ”€ Script with Â±1ms jitter: rhythm_consistency = 0.01 (1%)
â”œâ”€ Script with Â±2ms jitter: rhythm_consistency = 0.02 (2%)
â””â”€ All < 0.05 âœ— (easily detected)

Margin of Safety:
â”œâ”€ Real humans: 0.08 - 0.25 (well above 0.05)
â”œâ”€ Bots: 0.00 - 0.04 (well below 0.05)
â”œâ”€ Clear separation with no false positives
â””â”€ Threshold = 0.05 is safe cutoff
```

---

## 2.4 Ensemble Anomaly Detection (Gate 4)

### Two-Algorithm Ensemble

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Login Feature Vector                  â”‚
â”‚  [114.5, 36.1, 103.9, 268.7, 117.2, ...]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  ISOLATION     â”‚  â”‚     LOCAL      â”‚
         â”‚  FOREST (IF)   â”‚  â”‚   OUTLIER      â”‚
         â”‚                â”‚  â”‚   FACTOR (LOF) â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                  â”‚
         Anomaly Score 1     Anomaly Score 2
         (e.g., -0.8)        (e.g., -0.7)
                 â”‚                  â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Ensemble Decision:      â”‚
            â”‚                         â”‚
            â”‚ if (IF < threshold)     â”‚
            â”‚   AND (LOF < threshold) â”‚
            â”‚   â†’ REJECT             â”‚
            â”‚ else                    â”‚
            â”‚   â†’ ACCEPT             â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Algorithm 1: Isolation Forest

```
How Isolation Forest Works:

Step 1: Build Random Decision Trees
â”œâ”€ Select random feature (e.g., dwell_mean)
â”œâ”€ Select random threshold (e.g., 114 ms)
â”œâ”€ Split data: dwell_mean < 114 vs >= 114
â”œâ”€ Recursively repeat on subsets
â””â”€ Build 100 trees (n_estimators=100)

Intuition:
â”œâ”€ Normal points need many splits to isolate (deep in tree)
â”œâ”€ Anomalies need few splits to isolate (shallow in tree)
â”œâ”€ Anomaly score = average depth in forest
â””â”€ Shallow = anomaly, Deep = normal

Example:
Legitimate user features [114.5, 36.1, 103.9, ...]
â”œâ”€ Needs ~8 splits to isolate completely (normal point)
â”œâ”€ Anomaly score = 8/max_depth â‰ˆ 0.5

Impostor features [250.0, 50.0, 200.0, ...]
â”œâ”€ Needs only ~2 splits to isolate (very different)
â”œâ”€ Anomaly score = 2/max_depth â‰ˆ 0.125
â””â”€ Lower score = more anomalous
```

### Algorithm 2: Local Outlier Factor (LOF)

```
How LOF Works:

Step 1: Calculate Neighbor Distances
â”œâ”€ For each sample, find k-nearest neighbors (k=20)
â”œâ”€ Calculate distance to kth neighbor
â”œâ”€ Example: nearest 20 neighbors at avg distance = 0.5

Step 2: Calculate Local Reachability Density (LRD)
â”œâ”€ For each sample, calculate how "tightly" neighbors cluster
â”œâ”€ LRD high = tight cluster (normal point)
â”œâ”€ LRD low = isolated point (possible outlier)

Step 3: Compare to Neighbor's LRD
â”œâ”€ Calculate: LOF = (avg neighbor LRD) / (own LRD)
â”œâ”€ LOF â‰ˆ 1.0 = similar density to neighbors (normal)
â”œâ”€ LOF >> 1.0 = much lower density than neighbors (outlier)

Example:
Legitimate cluster:
â”œâ”€ All 20 neighbors have LRD â‰ˆ 0.5
â”œâ”€ Your LRD â‰ˆ 0.5
â”œâ”€ LOF = 0.5 / 0.5 = 1.0 â†’ NORMAL âœ“

Point in sparse region:
â”œâ”€ All 20 neighbors have LRD â‰ˆ 0.5
â”œâ”€ Your LRD â‰ˆ 0.1 (isolated)
â”œâ”€ LOF = 0.5 / 0.1 = 5.0 â†’ OUTLIER âœ—
```

### Why Ensemble (Both + AND Logic)?

```
Problem with Single Algorithm:
â”œâ”€ Isolation Forest alone:
â”‚  â””â”€ Sometimes misses cluster-based anomalies
â”‚  â””â”€ Good at global outliers, bad at local outliers
â”‚
â”œâ”€ LOF alone:
â”‚  â””â”€ Sometimes misses global anomalies
â”‚  â””â”€ Good at local outliers, bad at global outliers

Solution: Ensemble with AND Logic
â”œâ”€ Both must flag as anomaly to REJECT
â”œâ”€ If only one flags, ACCEPT (benefit of doubt)
â”œâ”€ Reduces false positives (legitimate users blocked)
â””â”€ Better than OR logic (which would reject too much)

Example:
Feature set looks globally normal but locally odd:
â”œâ”€ IF score: -0.7 (inside) âœ“
â”œâ”€ LOF score: +2.1 (outside) âœ—
â”œâ”€ Decision: AND logic â†’ Accept (one is normal)
â”œâ”€ User might have unusual but valid typing variation
â””â”€ Better to accept than reject

Feature set is clearly anomalous (both algorithms agree):
â”œâ”€ IF score: +1.5 (outside) âœ—
â”œâ”€ LOF score: +3.0 (outside) âœ—
â”œâ”€ Decision: AND logic â†’ Reject (both flag)
â”œâ”€ Clear impostor attempt detected
â””â”€ Confident rejection
```

### Threshold Calculation

```python
# From auth.py - _train_user_model()

# Thresholds are ADAPTIVE (per-user, not global)

# Calculate baseline scores on user's OWN samples
X_scaled = scaler.fit_transform(user_samples)
iso_scores = iso_forest.score_samples(X_scaled)  # Array of scores
lof_scores = lof.score_samples(X_scaled)         # Array of scores

# Dynamic threshold: mean - 2*std
iso_threshold = np.mean(iso_scores) - 2 * np.std(iso_scores)
# e.g., if iso_scores = [-0.8, -0.7, -0.9] for user's samples
# mean = -0.8, std = 0.08
# threshold = -0.8 - 2*0.08 = -0.96

lof_threshold = np.mean(lof_scores) - 2 * np.std(lof_scores)

# Login prediction:
iso_login_score = iso_forest.score_samples([login_features])
lof_login_score = lof.score_samples([login_features])

if (iso_login_score < iso_threshold) AND (lof_login_score < lof_threshold):
    reject = True  # Both flags anomaly
else:
    reject = False  # At least one is normal
```

### Example Scoring

```
User's Registration Samples:
Sample 1 features: [114.2, 36.1, 103.8, 268.5, ...]
Sample 2 features: [114.8, 36.2, 104.1, 268.9, ...]

Train on these 2 samples:
â”œâ”€ IF score on sample 1: -0.82
â”œâ”€ IF score on sample 2: -0.81
â”œâ”€ Mean = -0.815, Std = 0.007
â”œâ”€ IF Threshold = -0.815 - 2*0.007 = -0.829

â”œâ”€ LOF score on sample 1: -0.90
â”œâ”€ LOF score on sample 2: -0.91
â”œâ”€ Mean = -0.905, Std = 0.007
â”œâ”€ LOF Threshold = -0.905 - 2*0.007 = -0.919

Login Attempt 1 (Legitimate):
â”œâ”€ Login features: [114.5, 36.0, 103.9, 268.7, ...]
â”œâ”€ IF score: -0.80 > -0.829? YES (inside threshold) âœ“
â”œâ”€ LOF score: -0.91 > -0.919? YES (inside threshold) âœ“
â”œâ”€ Decision: At least one is normal? YES
â””â”€ Result: ACCEPT âœ“

Login Attempt 2 (Impostor):
â”œâ”€ Login features: [150.0, 50.0, 130.0, 300.0, ...]
â”œâ”€ IF score: +1.2 < -0.829? NO (outside threshold) âœ—
â”œâ”€ LOF score: +2.5 < -0.919? NO (outside threshold) âœ—
â”œâ”€ Decision: Both flag anomaly? YES
â””â”€ Result: REJECT âœ—
```

---

# PART 3: AI/ML - KEYSTROKE DYNAMICS & ADAPTIVE LEARNING

## 3.1 Feature Extraction (16 Dimensions)

### Raw Keystroke Events

```javascript
// Frontend captures these events:
{
    type: "keydown",           // or "keyup"
    key: "p",                  // character pressed
    code: "KeyP",              // key identifier
    timestamp: 1234567.890     // milliseconds since start
}

Array of events for "password":
[
    {type: "keydown", key: "p", code: "KeyP", timestamp: 0},
    {type: "keyup", key: "p", code: "KeyP", timestamp: 120},
    {type: "keydown", key: "a", code: "KeyA", timestamp: 268},
    {type: "keyup", key: "a", code: "KeyA", timestamp: 363},
    {type: "keydown", key: "s", code: "KeyS", timestamp: 628},
    {type: "keyup", key: "s", code: "KeyS", timestamp: 758},
    ... (continues for rest of password)
]
```

### Step 1: Pair Keydown and Keyup Events

```python
# From keystroke_features.py - _pair_key_events()

def _pair_key_events(events):
    """
    Goal: Calculate DWELL TIME for each key
    (how long finger is held down)
    """
    keydown_map = {}
    dwell_times = []

    for evt in events:
        if evt["type"] == "keydown":
            # Record when key went down
            keydown_map[evt["code"]] = evt["timestamp"]
            # keydown_map = {"KeyP": 0}

        elif evt["type"] == "keyup":
            # Find matching keydown
            start = keydown_map.pop(evt["code"], None)
            if start is not None:
                # Calculate dwell time
                dwell = evt["timestamp"] - start
                dwell_times.append(dwell)
                # dwell_times = [120, 95, 130, 90, 110, ...]

    return dwell_times  # [120, 95, 130, 90, 110]
```

### Step 2: Calculate Flight Times

```python
# From keystroke_features.py - _flight_times()

def _flight_times(events):
    """
    Goal: Calculate FLIGHT TIME between keystrokes
    (gap between when one key is released and next key pressed)
    """
    # Extract only keydown timestamps
    keydown_ts = [e["timestamp"] for e in events if e["type"] == "keydown"]
    # keydown_ts = [0, 268, 628, 1093, 1321, 2524]

    flights = []
    for i in range(1, len(keydown_ts)):
        # Calculate gap between consecutive keypresses
        flight = keydown_ts[i] - keydown_ts[i-1]
        flights.append(flight)
        # flight = 268 - 0 = 268 (time from "p" release to "a" press)

    return flights  # [268, 360, 465, 228, 1203]
```

### Step 3: Calculate Statistical Features

```python
# From keystroke_features.py - _safe_stats()

dwell_times = [120, 95, 130, 90, 110]

# Mean (average)
dwell_mean = sum(dwell_times) / len(dwell_times)
           = (120 + 95 + 130 + 90 + 110) / 5
           = 545 / 5
           = 109 ms

# Standard deviation (how much variation)
# Formula: sqrt(sum((x - mean)^2) / n)
deviations = [(120-109)^2, (95-109)^2, (130-109)^2, (90-109)^2, (110-109)^2]
           = [121, 196, 441, 361, 1]
variance = (121 + 196 + 441 + 361 + 1) / 5 = 224
dwell_std = sqrt(224) = 14.97 â‰ˆ 15 ms

# Median (middle value when sorted)
sorted_dwell = [90, 95, 110, 120, 130]
dwell_median = 110 ms (middle value)

Result:
â”œâ”€ dwell_mean = 109 ms
â”œâ”€ dwell_std = 15 ms
â””â”€ dwell_median = 110 ms

Similarly for flight_times:
â”œâ”€ flight_mean = 304 ms
â”œâ”€ flight_std = 119 ms
â””â”€ flight_median = 268 ms
```

### Step 4: Calculate Aggregate Features

```python
# From keystroke_features.py

# Total time (first keystroke to last keystroke)
first_ts = events[0]["timestamp"]       # 0 ms
last_ts = events[-1]["timestamp"]       # 2524 ms
total_time = last_ts - first_ts = 2524 ms

# Key count (number of keys pressed)
key_count = len([e for e in events if e["type"] == "keydown"])
          = 8 keys (for "password")

# Cadence (keystroke rate - keys per second)
cadence = key_count / total_time
        = 8 / 2524
        = 0.00317 keys/ms
        = 3.17 keys/second

# Rhythm consistency (measure of uniformity)
rhythm_consistency = flight_std / flight_mean
                   = 119 / 304
                   = 0.391

# Pressure variance (variation in dwell times)
pressure_variance = dwell_std
                  = 15 ms

# Dwell to flight ratio (hold time vs gap time)
dwell_flight_ratio = dwell_mean / flight_mean
                   = 109 / 304
                   = 0.358

# Dwell coefficient of variation
dwell_cv = dwell_std / dwell_mean
         = 15 / 109
         = 0.138

# Pattern entropy (randomness of key sequence)
key_sequence = ['p', 'a', 's', 's', 'w', 'o', 'r', 'd']
# Calculate transitions: (p,a), (a,s), (s,s), (s,w), (w,o), (o,r), (r,d)
# Measure how many unique transitions exist
# High entropy = varied key patterns
# Low entropy = repeated patterns
# Calculate using information theory formula
pattern_entropy â‰ˆ 0.99 (high - varied transitions)

# Key variation (unique keys / total keys)
unique_keys = len(set(['p', 'a', 's', 's', 'w', 'o', 'r', 'd']))
           = 7 unique keys
key_variation = 7 / 8 = 0.875

# Typing burstiness (are keypresses clustered or spread out?)
# Calculate coefficient of variation of flight times
typing_burstiness = std(flight_times) / mean(flight_times)
                  = 119 / 304
                  = 0.391
```

### Complete 16-Dimensional Feature Vector

```
Features extracted from "password" keystroke:

Index | Feature Name              | Value   | Unit
------|---------------------------|---------|----------
  1   | dwell_mean               | 109     | ms
  2   | dwell_std                | 15      | ms
  3   | dwell_median             | 110     | ms
  4   | flight_mean              | 304     | ms
  5   | flight_std               | 119     | ms
  6   | flight_median            | 268     | ms
  7   | total_time               | 2524    | ms
  8   | key_count                | 8       | keys
  9   | cadence                  | 0.00317 | keys/ms
  10  | rhythm_consistency       | 0.391   | ratio
  11  | pressure_variance        | 15      | ms
  12  | dwell_flight_ratio       | 0.358   | ratio
  13  | dwell_cv                 | 0.138   | ratio
  14  | pattern_entropy          | 0.99    | ratio (0-1)
  15  | key_variation            | 0.875   | ratio (0-1)
  16  | typing_burstiness        | 0.391   | ratio

Vector: [109, 15, 110, 304, 119, 268, 2524, 8, 0.00317, 0.391, 15, 0.358, 0.138, 0.99, 0.875, 0.391]
```

---

## 3.2 Feature Template vs Feature Std (users.json)

### Feature Template Creation

```
Registration Phase:

Sample 1 keystroke:
  features_1 = [114.2, 36.1, 103.8, 268.5, 117.1, 250.1, 2520, 10, 0.00397, 0.436, 36.1, 0.426, 0.316, 0.990, 0.900, 0.436]

Sample 2 keystroke:
  features_2 = [114.8, 36.2, 104.1, 268.9, 117.3, 250.3, 2528, 10, 0.00396, 0.436, 36.2, 0.427, 0.316, 0.999, 0.900, 0.436]

Feature Template (Average of 2 samples):
  template[i] = (features_1[i] + features_2[i]) / 2

  template[0] = (114.2 + 114.8) / 2 = 114.5 âœ“ (dwell_mean)
  template[1] = (36.1 + 36.2) / 2 = 36.15 âœ“ (dwell_std)
  template[2] = (103.8 + 104.1) / 2 = 103.95 âœ“ (dwell_median)
  ... etc for all 16 dimensions

  Result: feature_template = [114.5, 36.15, 103.95, 268.7, 117.2, 250.2, 2524, 10, 0.00397, 0.436, 36.15, 0.427, 0.316, 0.995, 0.900, 0.436]
```

### Feature Std Creation

```
Feature Standard Deviation (Measure of Variation):

  std[i] = sqrt(sum((features_j[i] - template[i])^2) / n_samples)

For dwell_mean (index 0):
  values = [114.2, 114.8]
  mean = 114.5
  deviations = [(114.2-114.5)^2, (114.8-114.5)^2] = [0.09, 0.09]
  variance = (0.09 + 0.09) / 2 = 0.09
  std = sqrt(0.09) = 0.3 ms

For flight_mean (index 3):
  values = [268.5, 268.9]
  mean = 268.7
  deviations = [(268.5-268.7)^2, (268.9-268.7)^2] = [0.04, 0.04]
  variance = (0.04 + 0.04) / 2 = 0.04
  std = sqrt(0.04) = 0.2 ms

Result: feature_std = [0.3, 0.05, 0.15, 0.2, 0.1, 0.1, 4, 0, 0.00001, 0.0, 0.05, 0.0005, 0.0, 0.0045, 0.0, 0.0]
```

### In users.json

```json
{
  "tanmay": {
    "feature_template": [
      114.5, 36.15, 103.95, 268.7, 117.2, 250.2, 2524, 10, 0.00397, 0.436,
      36.15, 0.427, 0.316, 0.995, 0.9, 0.436
    ],

    "feature_std": [
      0.3, 0.05, 0.15, 0.2, 0.1, 0.1, 4, 0, 0.00001, 0.0, 0.05, 0.0005, 0.0,
      0.0045, 0.0, 0.0
    ]
  }
}
```

### Interpretation

```
feature_template[0] = 114.5
  â†’ User's average dwell time is 114.5 ms
  â†’ "This is what normal looks like for this user"

feature_std[0] = 0.3
  â†’ Natural variation in dwell time is Â±0.3 ms
  â†’ Each login's dwell_mean might be 114.2 to 114.8 ms

feature_template[3] = 268.7
  â†’ User's average gap between keys is 268.7 ms
  â†’ "This is their normal typing speed"

feature_std[3] = 0.2
  â†’ Natural variation in flight time is Â±0.2 ms
  â†’ Each login's flight_mean might be 268.5 to 268.9 ms
```

### How They're Used

```
On Login:

Step 1: Extract new features
  login_features = [114.3, 36.1, 103.9, 268.5, ...]

Step 2: Check if within acceptable range
  For each feature i:
    lower_bound[i] = template[i] - 3 * std[i]
    upper_bound[i] = template[i] + 3 * std[i]

  Example (feature 0 - dwell_mean):
    lower = 114.5 - 3*0.3 = 113.6 ms
    upper = 114.5 + 3*0.3 = 115.4 ms
    login = 114.3 ms
    is_valid = (113.6 < 114.3 < 115.4) = True âœ“

Step 3: Update template on success
  new_template[i] = 0.85 * old_template[i] + 0.15 * login_features[i]
  # 85% keeps old pattern, 15% learns new pattern

  new_std[i] updated based on all samples so far
```

---

## 3.3 Dual Sampling Registration

### Why Two Passwords?

```
Design Decision: Capture password TWICE during registration

Reason 1: Establish Baseline Variation
â”œâ”€ First password entry: User types "MyPassword123!"
â”œâ”€ Second password entry: User types same password again
â”œâ”€ These capture how much the user naturally varies
â”œâ”€ Even the same user doesn't type identically twice
â””â”€ This variation becomes acceptable range

Reason 2: Minimum Samples for SVM
â”œâ”€ One-Class SVM needs minimum 2 samples to train
â”œâ”€ Can't generalize from single example
â”œâ”€ Two samples = minimum viable dataset
â””â”€ Captures at least one data point

Reason 3: Early Detection of Stress/Issues
â”œâ”€ If user can't reproduce their typing, it's a signal
â”œâ”€ Maybe they forgot their password (stress changes typing)
â”œâ”€ Maybe they're being coerced to register
â””â”€ System can detect and warn

Reason 4: Detect Registration Anomalies
â”œâ”€ If first and second password have very different features
â”œâ”€ â†’ User might not have full control of typing
â”œâ”€ â†’ System can flag for further verification
â””â”€ Early security check
```

### Registration Flow with Dual Sampling

```
User Registration:

1. Username: "tanmay"
   â”œâ”€ Password strength check: OK
   â””â”€ Continue

2. Enter Password First Time:
   â”œâ”€ User types: "MyPassword123!"
   â”œâ”€ Frontend captures all keystroke events
   â”œâ”€ JavaScript timestamps each keydown/keyup
   â””â”€ Example: 120+ events stored

3. Extract Features from First Entry:
   â”œâ”€ Parse keystroke events
   â”œâ”€ Calculate 16-dimensional feature vector
   â”œâ”€ Result: features_vec_1 = [114.2, 36.1, 103.8, ...]
   â””â”€ Save to "passwordSamples" array (frontend)

4. Confirm Password Second Time:
   â”œâ”€ User types: "MyPassword123!" (again)
   â”œâ”€ Frontend captures all keystroke events again
   â”œâ”€ JavaScript timestamps each event
   â””â”€ Example: 120+ events stored

5. Extract Features from Second Entry:
   â”œâ”€ Parse keystroke events
   â”œâ”€ Calculate 16-dimensional feature vector
   â”œâ”€ Result: features_vec_2 = [114.8, 36.2, 104.1, ...]
   â””â”€ Save to "passwordSamples" array

6. Send to Backend:
   â”œâ”€ POST /api/register
   â”œâ”€ Payload: {
   â”‚    username: "tanmay",
   â”‚    password: "MyPassword123!",
   â”‚    passwordSamples: [
   â”‚        {keystrokes: [events1...]},
   â”‚        {keystrokes: [events2...]}
   â”‚    ]
   â”‚  }
   â””â”€ Include BOTH sets of raw events

7. Backend Processing:
   â”œâ”€ Extract features from sample 1: [114.2, 36.1, 103.8, ...]
   â”œâ”€ Extract features from sample 2: [114.8, 36.2, 104.1, ...]
   â”‚
   â”œâ”€ Create template (average):
   â”‚  feature_template = [(114.2+114.8)/2, (36.1+36.2)/2, ...]
   â”‚                   = [114.5, 36.15, 103.95, ...]
   â”‚
   â”œâ”€ Create std (variation):
   â”‚  feature_std = [std(114.2, 114.8), std(36.1, 36.2), ...]
   â”‚              = [0.3, 0.05, 0.15, ...]
   â”‚
   â”œâ”€ Train One-Class SVM:
   â”‚  SVM.fit([features_1, features_2])
   â”‚  Creates behavioral envelope
   â”‚
   â”œâ”€ Save both samples to CSV:
   â”‚  username | label | session_id | keystrokes | features
   â”‚  tanmay   | 1     | tanmay_reg_0 | {...}    | [...]
   â”‚  tanmay   | 1     | tanmay_reg_1 | {...}    | [...]
   â”‚
   â”œâ”€ Generate crypto keys:
   â”‚  private_key, public_key = RSA_generate()
   â”‚
   â”œâ”€ Create binding token:
   â”‚  binding_token = bind_public_key(public_key, feature_template)
   â”‚
   â””â”€ Save to users.json:
      {
        "tanmay": {
          "password_hash": "...",
          "public_key": "...",
          "private_key": "...",
          "binding_token": "...",
          "feature_template": [114.5, 36.15, ...],
          "feature_std": [0.3, 0.05, ...],
          "user_model": "<serialized SVM>",
          "model_samples_count": 2,
          "registration_date": 1234567890.123,
          "last_login": null,
          "login_count": 0,
          "failed_attempts": 0
        }
      }
```

---

## 3.4 One-Class SVM (Behavioral Envelope)

### What is One-Class SVM?

```
Traditional SVM:
â”œâ”€ Learn decision boundary between Class A and Class B
â”œâ”€ Requires examples of both classes
â”œâ”€ Example: spam vs not-spam emails
â””â”€ Supervised learning (needs labeled training data)

One-Class SVM:
â”œâ”€ Learn what "normal" looks like (one class only)
â”œâ”€ Doesn't need examples of anomalies
â”œâ”€ Example: "This is what legitimate login looks like"
â”œâ”€ Semi-supervised learning (learns from positives only)

Perfect for biometric auth:
â”œâ”€ We have many samples of legitimate user keystroke
â”œâ”€ We DON'T have samples of impostor keystroke
â”œâ”€ One-Class SVM learns "legitimate" boundary
â””â”€ Anything outside = rejected
```

### One-Class SVM Algorithm (Simplified)

```
Input: Training samples (all legitimate)
  X = [sample_1, sample_2, sample_3, ...]
      [114.2, 36.1, 103.8, ...]
      [114.8, 36.2, 104.1, ...]
      ... more samples ...

Step 1: Map to High-Dimensional Space
â”œâ”€ Use RBF (Radial Basis Function) kernel
â”œâ”€ Maps 16-D input to potentially infinite-D space
â”œâ”€ In high-D space, points spread out more
â””â”€ Easier to find separating boundary

Step 2: Find Maximum Margin Hypersurface
â”œâ”€ Create a hypersurface that separates "normal" from origin
â”œâ”€ Keep all training samples on one side
â”œâ”€ Maximize margin (distance from boundary)
â”œâ”€ Allow some violations (soft margin, C parameter)
â””â”€ Result: A support vector machine

Step 3: Decision Function
â”œâ”€ For new sample: f(x) = sum(alpha_i * K(support_vector, x)) - rho
â”œâ”€ If f(x) >= 0: Inside boundary â†’ LEGITIMATE
â”œâ”€ If f(x) < 0: Outside boundary â†’ ANOMALOUS
â””â”€ |f(x)| = confidence score

Visualization (2D simplified):
```

### Example with Registration

```
Registration with 2 samples:

Sample 1: [114.2, 36.1, 103.8, 268.5, ...]
Sample 2: [114.8, 36.2, 104.1, 268.9, ...]

Train One-Class SVM:
1. Feature scaling (normalize to 0-1)
2. RBF kernel mapping
3. Find boundary that encloses both samples with margin
4. Store support vectors + decision boundary

Resulting Decision Function:
â”œâ”€ For sample 1: f(sample_1) = +0.85 (clearly inside)
â”œâ”€ For sample 2: f(sample_2) = +0.90 (clearly inside)
â”œâ”€ For user's normal login: f(normal) â‰ˆ +0.6 (inside, slight variation)
â”œâ”€ For impostor: f(impostor) â‰ˆ -0.5 (outside, rejected)
â””â”€ Threshold decision: f(x) >= 0 â†’ Accept

Test Scenarios:

Scenario 1: Legitimate User Login
â”œâ”€ Features: [114.5, 36.0, 103.9, 268.7, ...] (natural variation)
â”œâ”€ SVM decision score: f(x) = +0.7
â”œâ”€ Is f(x) >= 0? YES
â””â”€ Result: ACCEPT âœ“

Scenario 2: Impostor with Different Pattern
â”œâ”€ Features: [150.0, 50.0, 130.0, 300.0, ...] (very different)
â”œâ”€ SVM decision score: f(x) = -0.8
â”œâ”€ Is f(x) >= 0? NO
â””â”€ Result: REJECT âœ—

Scenario 3: Legitimate User, Bad Day
â”œâ”€ Features: [120.0, 40.0, 110.0, 280.0, ...] (more variation than usual)
â”œâ”€ SVM decision score: f(x) = +0.2
â”œâ”€ Is f(x) >= 0? YES (barely inside)
â””â”€ Result: ACCEPT âœ“ (model tolerates reasonable variation)
```

### Model Storage and Loading

```python
# In auth.py - _train_user_model()

trained_model = {
    'svm': OneClassSVM(...),        # The actual model
    'scaler': StandardScaler(...),  # Feature scaling
    'threshold': 0.0                # Decision boundary
}

# Serialize to base64
model_serialized = base64.b64encode(
    joblib.dumps(trained_model)
).decode()

# Store in users.json
users_json["username"]["user_model"] = model_serialized

# Later, load for prediction
model_loaded = joblib.loads(
    base64.b64decode(users_json["username"]["user_model"])
)

# Make prediction
score = model_loaded['svm'].decision_function([new_features])
decision = "ACCEPT" if score >= 0 else "REJECT"
```

---

## 3.5 Adaptive Learning (Auto-Retraining)

### The Innovation: Continuous Model Improvement

```
Traditional Authentication:
â”œâ”€ Register: Train model once
â”œâ”€ Login: Use same model forever
â”œâ”€ Problem: Model gets stale, user's typing evolves
â”œâ”€ Result: Increasing false rejections over time

Adaptive Learning:
â”œâ”€ Register: Train initial model
â”œâ”€ Every successful login: Retrain with new sample
â”œâ”€ Problem solved: Model evolves with user
â”œâ”€ Result: Accuracy improves over time
```

### Step-by-Step Adaptive Learning Process

```
Login Attempt Successful (All 6 gates pass):

STEP 1: Save Raw Data to CSV
â”œâ”€ Append to data/keystrokes.csv:
â”œâ”€ user_id=tanmay
â”œâ”€ label=1 (legitimate)
â”œâ”€ session_id=tanmay_1769708400_success_login
â”œâ”€ keystrokes=[array of events]
â”œâ”€ features=[16-D feature vector]
â””â”€ Result: CSV grows from 24 rows to 25 rows

STEP 2: Load All User's Legitimate Samples
â”œâ”€ Query CSV for: user_id="tanmay" AND label=1
â”œâ”€ Retrieve: [sample_1, sample_2, ..., sample_25] (all past & current)
â”œâ”€ Parse features from each row
â””â”€ Result: 25 feature vectors

STEP 3: Retrain Model with Expanded Dataset
â”œâ”€ New training data:
â”‚  Sample 1 (reg): [114.2, 36.1, 103.8, ...]
â”‚  Sample 2 (reg): [114.8, 36.2, 104.1, ...]
â”‚  Sample 3 (login 1): [114.5, 36.0, 103.9, ...]
â”‚  ...
â”‚  Sample 25 (login 23): [114.7, 36.1, 103.8, ...]
â”‚
â”œâ”€ Train new One-Class SVM on all 25 samples
â”œâ”€ Update decision boundary (now based on larger dataset)
â”œâ”€ Calculate new thresholds
â””â”€ Result: Improved model

STEP 4: Update Feature Template
â”œâ”€ New template = weighted average:
â”‚  new_template[i] = 0.85 * old_template[i] + 0.15 * current_features[i]
â”‚
â”‚  Example (dwell_mean):
â”‚  old_template = 114.5
â”‚  current = 114.3 (this login)
â”‚  new_template = 0.85 * 114.5 + 0.15 * 114.3
â”‚               = 97.325 + 17.145
â”‚               = 114.47 (slightly adapted)
â”‚
â”œâ”€ 85% weight = Keep established pattern (damping)
â”œâ”€ 15% weight = Allow learning (adaptation rate)
â””â”€ Result: Template gradually evolves

STEP 5: Update Feature Std (Variation)
â”œâ”€ Calculate new standard deviation from all 25 samples
â”œâ”€ New std = stddev([sample_1, sample_2, ..., sample_25])
â”œâ”€ Example (dwell_mean):
â”‚  old_std = 0.3 (based on 2 samples)
â”‚  new_std = 0.4 (based on 25 samples, more realistic variation)
â”‚
â””â”€ Result: More accurate variation measurement

STEP 6: Reserialize and Save to users.json
â”œâ”€ Serialize updated model to base64
â”œâ”€ Update in users.json:
â”‚  {
â”‚    "tanmay": {
â”‚      "user_model": "<new_serialized_model>",
â”‚      "feature_template": [114.47, 36.12, ...],  # Updated
â”‚      "feature_std": [0.4, 0.06, ...],           # Updated
â”‚      "model_samples_count": 25                  # Updated
â”‚    }
â”‚  }
â”‚
â””â”€ Result: Ready for next login

STEP 7: Update Statistics
â”œâ”€ Increment login_count: 23 â†’ 24
â”œâ”€ Update last_login timestamp
â””â”€ Keep failed_attempts at 0
```

### Learning Rate Analysis

```
Learning Formula: new_value = 0.85 * old + 0.15 * current

Why 0.85 / 0.15 split?

Case 1: User's natural typing change
â”œâ”€ Over 20 logins, user's dwell_mean gradually increases
â”œâ”€ Each login: new = 0.85 * old + 0.15 * current
â”œâ”€ Login 1: 114.5 â†’ 114.5
â”œâ”€ Login 2: 0.85*114.5 + 0.15*116 = 114.725
â”œâ”€ Login 3: 0.85*114.725 + 0.15*117 = 114.966
â”œâ”€ Login 20: â‰ˆ 115.5 (template gradually adapted)
â””â”€ Result: Model tracks user's natural evolution

Case 2: One-off anomaly
â”œâ”€ User had one day of unusual typing (tired, sick)
â”œâ”€ dwell_mean = 150 (unusually high)
â”œâ”€ new = 0.85 * 114.5 + 0.15 * 150
â”‚    = 97.325 + 22.5
â”‚    = 119.825
â”œâ”€ Template bumped up only slightly (5.3 ms)
â”œâ”€ Next day back to normal: 0.85*119.825 + 0.15*114
â”‚                         = 101.85 + 17.1
â”‚                         = 118.95
â””â”€ Gradually returns to baseline (not over-adapted)

Why not higher learning rate?
â”œâ”€ If 0.5/0.5: Model too reactive to single anomalies
â”œâ”€ If 0.9/0.1: Model too slow to adapt to real changes
â”œâ”€ If 0.85/0.15: Goldilocks balance
â””â”€ Proven effective in literature
```

### Model Quality Improvement Over Time

```
Timeline: User "tanmay"

Registration (Samples: 2)
â”œâ”€ Baseline accuracy: ~85%
â”œâ”€ False positive rate: ~15% (legitimate rejected)
â”œâ”€ False negative rate: ~5% (impostor accepted)
â””â”€ Reason: Too few samples, large uncertainty

After 5 Successful Logins (Samples: 7)
â”œâ”€ Accuracy: ~90%
â”œâ”€ False positive rate: ~8%
â”œâ”€ False negative rate: ~2%
â””â”€ Reason: More data, pattern clearer

After 10 Logins (Samples: 12)
â”œâ”€ Accuracy: ~95%
â”œâ”€ False positive rate: ~4%
â”œâ”€ False negative rate: ~1%
â””â”€ Reason: Good training set, model stable

After 20+ Logins (Samples: 22+)
â”œâ”€ Accuracy: ~98%
â”œâ”€ False positive rate: <1%
â”œâ”€ False negative rate: <1%
â””â”€ Reason: Comprehensive training data

Current State (Samples: 25 - 23 logins + 2 registration)
â”œâ”€ model_samples_count: 25
â”œâ”€ login_count: 23
â”œâ”€ estimated_accuracy: ~99%
â”œâ”€ Peak performance reached
â””â”€ System fully adapted to user
```

---

## 3.6 Data Growth in data/keystrokes.csv

### File Structure

```csv
user_id    label   session_id                       keystrokes                    features
tanmay     1       tanmay_1768127943_register_0    [{...keystroke events...}]    [114.2, 36.1, ...]
tanmay     1       tanmay_1768127943_register_1    [{...keystroke events...}]    [114.8, 36.2, ...]
tanmay     1       tanmay_1769000000_success_login [{...keystroke events...}]    [114.5, 36.0, ...]
tanmay     0       tanmay_1769000100_fail_pw       [{...keystroke events...}]    [200.0, 50.0, ...]
tanmay     1       tanmay_1769000200_success_login [{...keystroke events...}]    [114.7, 36.1, ...]
tanmay     0       tanmay_1769000300_entropy_attack [{...keystroke events...}]    [114.5, 0.1, ...]
... (continues growing with each login attempt)
```

### Growth Pattern

```
Day 1 (Registration):
â”œâ”€ Row 1: Sample 1 (register_0)
â”œâ”€ Row 2: Sample 2 (register_1)
â””â”€ Total rows: 2

Day 2-5 (5 successful logins):
â”œâ”€ Row 3-7: 5 new successful login records
â””â”€ Total rows: 7

Day 6-10 (5 more successful logins + 2 failed):
â”œâ”€ Row 8-14: 7 new records
â””â”€ Total rows: 14

Day 11-23 (13 more attempts, 11 successful + 2 failed):
â”œâ”€ Row 15-27: 13 new records
â””â”€ Total rows: 27

Current state:
â”œâ”€ Total rows: 27
â”œâ”€ Legitimate (label=1): 25
â”œâ”€ Failed (label=0): 2
â”œâ”€ Models trained on: 25 legitimate samples
â””â”€ Failure analysis: 2 attempts analyzed (tempo_attack, fail_pw)
```

### Using CSV for Model Training

```python
# Load legitimate samples only:

df = pd.read_csv("data/keystrokes.csv", sep="\t")
user_data = df[(df['user_id'] == 'tanmay') & (df['label'] == 1)]

# Result: 25 rows of all successful attempts
# Extract features from each:

feature_vectors = []
for _, row in user_data.iterrows():
    features = json.loads(row['features'])
    feature_vectors.append(features)

# feature_vectors = [[114.2, 36.1, ...], [114.8, 36.2, ...], ...]
# Shape: (25, 16)

# Train model on this 25x16 matrix:
X = np.array(feature_vectors)
model.fit(X)
```

---

## 3.7 Complete Feature Engineering Summary

### All 16 Features at a Glance

| Feature            | Measures                | Detection Power      | Example       |
| ------------------ | ----------------------- | -------------------- | ------------- |
| dwell_mean         | Avg hold time           | User's natural speed | 114ms         |
| dwell_std          | Hold time variation     | Consistency          | 15ms (Â±13%)   |
| dwell_median       | Middle hold time        | Distribution shape   | 110ms         |
| flight_mean        | Avg gap between keys    | Typing speed         | 268ms         |
| flight_std         | Gap variation           | Rhythm naturalness   | 119ms         |
| flight_median      | Middle gap              | Distribution         | 250ms         |
| total_time         | Time for whole password | Tempo                | 2524ms        |
| key_count          | Number of keypresses    | Password length      | 8 keys        |
| cadence            | Keys per second         | Typing rate          | 3.2 keys/sec  |
| rhythm_consistency | flight_std/flight_mean  | Bot detection        | 0.44 (44%)    |
| pressure_variance  | dwell_std               | Firmness variation   | 15ms          |
| dwell_flight_ratio | Hold/gap ratio          | Typing style         | 0.43          |
| dwell_cv           | dwell_std/dwell_mean    | Hold consistency     | 0.13          |
| pattern_entropy    | Key sequence randomness | Behavioral pattern   | 0.99 (varied) |
| key_variation      | Unique keys / total     | Letter diversity     | 0.875         |
| typing_burstiness  | Clustering of presses   | Burst vs steady      | 0.39          |

---

## 3.8 Model Ensemble Scoring

### How Two Models Vote

```python
# At login, both models score the features:

login_features = [114.3, 36.1, 103.9, 268.5, ...]

# Model 1: Isolation Forest
iso_score = iso_forest.score_samples([login_features])
# Result: -0.7 (inside envelope, negative means normal)

# Model 2: Local Outlier Factor
lof_score = lof.score_samples([login_features])
# Result: -0.8 (inside envelope)

# Thresholds (calculated from user's own samples):
iso_threshold = -0.96
lof_threshold = -0.92

# Decision Logic (AND):
if (iso_score < iso_threshold) AND (lof_score < lof_threshold):
    # Both models flag as anomaly
    decision = "REJECT"
else:
    # At least one model says it's normal
    decision = "ACCEPT"

# In this example:
# iso_score (-0.7) > iso_threshold (-0.96)? YES (inside, not anomaly)
# lof_score (-0.8) > lof_threshold (-0.92)? YES (inside, not anomaly)
# Decision: ACCEPT âœ“
```

### Ensemble Advantage

```
Single Model Problems:

IF only (no LOF):
â”œâ”€ Case A: Global anomaly detected, Local normal â†’ REJECT
â”œâ”€ Case B: Global normal, Micro-cluster anomaly â†’ ACCEPT
â””â”€ Sometimes misses micro-clusters

LOF only (no IF):
â”œâ”€ Case A: Global anomaly detected, Local cluster outlier â†’ ACCEPT
â”œâ”€ Case B: Global anomaly, Local cluster normal â†’ ACCEPT
â””â”€ Sometimes misses global anomalies

Ensemble (IF + LOF with AND):
â”œâ”€ Case A: IFâ†’reject, LOFâ†’accept â†’ ACCEPT (benefit of doubt)
â”œâ”€ Case B: IFâ†’accept, LOFâ†’reject â†’ ACCEPT (benefit of doubt)
â”œâ”€ Case C: Bothâ†’reject â†’ REJECT (certain anomaly)
â””â”€ Best of both worlds
```

---

_End of Deep Technical Explanation_
